# План рефакторинга нормализации путей и управления проектами

**Author**: Vasiliy Zdanovskiy  
**Email**: vasilyvz@gmail.com  
**Date**: 2026-01-09

## Цель рефакторинга

Унифицировать нормализацию путей, создать единый метод определения корня проекта, внедрить менеджер проектов и обеспечить валидацию project_id на всех этапах работы с файлами.

## Текущие проблемы

1. **Разные методы нормализации путей** в разных местах кода
2. **Отсутствие единого метода определения корня проекта** по projectid
3. **Нет валидации project_id** при восстановлении и обновлении файлов
4. **Формат projectid** - простой текст вместо JSON
5. **Отсутствие менеджера проектов** для централизованного управления
6. **Множественные места обращения к файловой системе** без единой точки входа

## Пошаговый план рефакторинга

**⚠️ КРИТИЧЕСКИ ВАЖНО: Тестирование**
- Покрытие тестами: **90%+** для всех новых компонентов
- Использование реальных данных из `test_data/` подкаталогов (vast_srv, bhlff, code_analysis)
- Интеграционные тесты на реальных проектах
- Тесты производительности и граничных случаев
- Регрессионные тесты для обратной совместимости
- Подробности в разделе "Этап 10: Детальное тестирование с покрытием 90%+"

### Этап 1: Консолидация всех исключений в один файл

**Файл**: `code_analysis/core/exceptions.py` (обновить существующий)

**Текущие исключения в проекте**:
- `code_analysis/core/exceptions.py`: `CodeAnalysisError`, `ValidationError`, `RefactoringError`, `DatabaseError`, `DatabaseOperationError`, `AnalysisError`, `ConfigurationError`
- `code_analysis/core/project_resolution.py`: `ProjectIdError`
- `code_analysis/core/project_discovery.py`: `NestedProjectError`, `DuplicateProjectIdError`
- `code_analysis/core/cst_module/errors.py`: `CSTModulePatchError`
- `code_analysis/cst_query/errors.py`: `QueryParseError`

**Новые исключения для проектов**:
- `MultipleProjectIdError` - несколько projectid файлов в пути
- `ProjectIdMismatchError` - несоответствие project_id из файла и базы
- `ProjectNotFoundError` - проект не найден
- `InvalidProjectIdFormatError` - неверный формат projectid файла
- `GitOperationError` - ошибка при работе с git

**Действия**:
1. Объединить все исключения в `code_analysis/core/exceptions.py`
2. Перенести `ProjectIdError`, `NestedProjectError`, `DuplicateProjectIdError` из других модулей
3. Перенести `CSTModulePatchError`, `QueryParseError`
4. Добавить новые типы исключений для проектов
5. Обновить все импорты во всех местах использования
6. Удалить старые файлы с исключениями после миграции

---

### Этап 2: Изменение формата projectid на JSON

**Текущий формат**: Простой текст с UUID4
```
550e8400-e29b-41d4-a716-446655440000
```

**Новый формат**: JSON
```json
{
    "id": "550e8400-e29b-41d4-a716-446655440000",
    "description": "Human readable description of project"
}
```

**Файлы для изменения**:
- `code_analysis/core/project_resolution.py` - `load_project_id()`
- `code_analysis/core/project_discovery.py` - использование `load_project_id()`
- Все тесты, использующие projectid

**Действия**:
1. Обновить `load_project_id()` для чтения JSON
2. Добавить функцию `load_project_info()` для чтения полной информации о проекте
3. Добавить валидацию JSON структуры
4. Обновить тесты
5. Создать миграционный скрипт для обновления существующих projectid файлов

---

### Этап 3: Создание единого метода определения корня проекта

**Файл**: `code_analysis/core/project_resolution.py`

**Новый метод**: `find_project_root_for_path(file_path: Path, watch_dirs: List[Path]) -> Optional[ProjectInfo]`

**Структура возврата**:
```python
@dataclass
class ProjectInfo:
    """Information about project root."""
    root_path: Path  # Абсолютный путь к корню
    project_id: str  # UUID4 идентификатор
    description: str  # Текстовое описание проекта
```

**Требования**:
- Должен возвращать ошибку, если в пути есть несколько projectid файлов
- Должен возвращать `None`, если проект не найден
- Должен использовать единую логику с `find_project_root()` из `project_discovery.py`

**Действия**:
1. Создать `ProjectInfo` dataclass
2. Реализовать `find_project_root_for_path()` с проверкой на множественные projectid
3. Обновить `find_project_root()` для использования нового метода
4. Добавить тесты для проверки множественных projectid

---

### Этап 3.5: Создание файла констант и менеджера настроек

**Файлы**: 
- `code_analysis/core/constants.py` (новый) - все константы проекта
- `code_analysis/core/settings_manager.py` (новый) - менеджер настроек с приоритетом

**Приоритет настроек**:
1. CLI аргументы (наивысший приоритет)
2. Переменные среды (средний приоритет)
3. Константы (значения по умолчанию)

**SettingsManager**:
- Singleton паттерн для единого экземпляра
- Автоматическая загрузка из переменных среды (префикс `CODE_ANALYSIS_`)
- Метод `set_cli_overrides()` для установки CLI аргументов
- Метод `get()` для получения настроек с учетом приоритета
- Удобные свойства для часто используемых настроек
- Функция `get_settings()` для получения глобального экземпляра

**Категории констант**:

1. **Файловые расширения**:
   - `CODE_FILE_EXTENSIONS` - расширения файлов для обработки
   - `CONFIG_FILE_EXTENSIONS` - расширения конфигурационных файлов

2. **Игнорируемые паттерны**:
   - `DEFAULT_IGNORE_PATTERNS` - паттерны для игнорирования при сканировании
   - `GIT_IGNORE_PATTERNS` - паттерны для .gitignore

3. **Имена файлов и директорий**:
   - `PROJECTID_FILENAME` - имя файла projectid ("projectid")
   - `GIT_DIR_NAME` - имя директории .git (".git")
   - `VERSIONS_DIR_NAME` - имя директории для версий ("data/versions")
   - `LOCKS_DIR_NAME` - имя директории для блокировок ("data/locks")
   - `LOGS_DIR_NAME` - имя директории для логов ("logs")
   - `DATA_DIR_NAME` - имя директории для данных ("data")

4. **Размеры и лимиты**:
   - `DEFAULT_MAX_FILE_LINES` - максимальное количество строк в файле (400)
   - `DEFAULT_MIN_CHUNK_LENGTH` - минимальная длина чанка (30)
   - `DEFAULT_LOG_MAX_BYTES` - максимальный размер лог-файла (10485760 = 10 MB)
   - `DEFAULT_LOG_BACKUP_COUNT` - количество резервных копий логов (5)
   - `DEFAULT_VECTOR_DIM` - размерность вектора (384)

5. **Таймауты и интервалы**:
   - `DEFAULT_POLL_INTERVAL` - интервал опроса в секундах (30)
   - `DEFAULT_SCAN_INTERVAL` - интервал сканирования в секундах (60)
   - `DEFAULT_RETRY_ATTEMPTS` - количество попыток повтора (3)
   - `DEFAULT_RETRY_DELAY` - задержка между попытками в секундах (10.0)
   - `DEFAULT_COMMAND_TIMEOUT` - таймаут команды в секундах (60.0)
   - `DEFAULT_GIT_TIMEOUT` - таймаут git команд в секундах (10.0)

6. **Паттерны для анализа**:
   - `PLACEHOLDER_PATTERNS` - паттерны для поиска плейсхолдеров (TODO, FIXME, etc.)
   - `STUB_PATTERNS` - паттерны для поиска заглушек

7. **Порты и хосты**:
   - `DEFAULT_SERVER_PORT` - порт сервера по умолчанию (15000)
   - `DEFAULT_SERVER_HOST` - хост сервера по умолчанию ("0.0.0.0")
   - `DEFAULT_CHUNKER_PORT` - порт чанкера по умолчанию (8009)
   - `DEFAULT_EMBEDDING_PORT` - порт сервиса эмбеддингов по умолчанию (8001)

8. **Circuit Breaker**:
   - `DEFAULT_FAILURE_THRESHOLD` - порог отказов (5)
   - `DEFAULT_RECOVERY_TIMEOUT` - таймаут восстановления (60.0)
   - `DEFAULT_SUCCESS_THRESHOLD` - порог успешных запросов (2)
   - `DEFAULT_INITIAL_BACKOFF` - начальная задержка (5.0)
   - `DEFAULT_MAX_BACKOFF` - максимальная задержка (300.0)
   - `DEFAULT_BACKOFF_MULTIPLIER` - множитель задержки (2.0)

9. **Batch Processor**:
   - `DEFAULT_BATCH_SIZE` - размер батча (10)
   - `DEFAULT_MAX_EMPTY_ITERATIONS` - максимальное количество пустых итераций (3)
   - `DEFAULT_EMPTY_DELAY` - задержка при пустых итерациях (5.0)

10. **Пути к файлам**:
    - `DEFAULT_DB_PATH` - путь к базе данных по умолчанию ("data/code_analysis.db")
    - `DEFAULT_FAISS_DIR` - директория для FAISS индексов ("data/faiss")
    - `DEFAULT_DYNAMIC_WATCH_FILE` - файл динамических watch_dirs ("data/dynamic_watch_dirs.json")
    - `DEFAULT_VECTORIZATION_WORKER_LOG` - лог векторизатора ("logs/vectorization_worker.log")
    - `DEFAULT_FILE_WATCHER_LOG` - лог файлвочера ("logs/file_watcher.log")

**Действия**:
1. ✅ Создать файл `constants.py` - выполнено
2. ✅ Создать файл `settings_manager.py` - выполнено
3. Вынести все хардкоды из кода в константы
4. Обновить все места использования хардкодов для использования `get_settings()`
5. Добавить документацию к константам
6. Обновить `config.py` для использования SettingsManager
7. Обновить `main.py` для передачи CLI аргументов в SettingsManager
8. Обновить все модули для использования `get_settings()` вместо прямого доступа к константам

**Примеры использования SettingsManager**:

```python
from code_analysis.core.settings_manager import get_settings, get_setting

# Получить глобальный экземпляр
settings = get_settings()

# Установить CLI переопределения (в main.py)
settings.set_cli_overrides({
    "server_port": 16000,
    "poll_interval": 60,
    "batch_size": 20,
})

# Получить настройку (приоритет: CLI > ENV > Constants)
port = settings.get("server_port")  # Вернет 16000 если установлено через CLI
poll_interval = settings.poll_interval  # Использование свойства

# Быстрый доступ через функцию
max_lines = get_setting("max_file_lines")  # Вернет значение с учетом приоритета

# Переменные среды (автоматически загружаются при инициализации)
# CODE_ANALYSIS_SERVER_PORT=16000
# CODE_ANALYSIS_POLL_INTERVAL=60
```

**Интеграция с main.py**:

```python
# В main.py после парсинга аргументов
from code_analysis.core.settings_manager import get_settings

settings = get_settings()
cli_overrides = {}
if args.port:
    cli_overrides["server_port"] = args.port
if args.host:
    cli_overrides["server_host"] = args.host
# ... другие CLI аргументы
settings.set_cli_overrides(cli_overrides)
```

---

### Этап 4: Создание менеджера проектов

**Файл**: `code_analysis/core/project_manager.py` (новый)

**Класс**: `ProjectManager`

**Методы**:
- `get_project_list() -> List[ProjectInfo]` - получение списка проектов
- `get_project_info(project_id: str) -> Optional[ProjectInfo]` - получение информации о проекте
- `create_project(root_path: Path, description: str, init_git: bool = False) -> ProjectInfo` - создание проекта
  - `init_git`: если True, создает git репозиторий в корне проекта
  - Использует `code_analysis.core.git_integration` для работы с git
- `validate_project_id(root_path: Path, project_id: str) -> bool` - валидация project_id

**Интеграция с git**:
- Использовать `git_integration.py` для проверки наличия git
- При `init_git=True`:
  1. Проверить доступность git через `is_git_available()`
  2. Проверить, что директория не является git репозиторием (`is_git_repository()`)
  3. Вызвать `git init` в корне проекта
  4. Создать базовый `.gitignore` с паттернами из `constants.py`:
     - `DEFAULT_IGNORE_PATTERNS` - стандартные паттерны
     - `GIT_IGNORE_PATTERNS` - дополнительные паттерны для git
  5. Добавить `.gitignore` и `projectid` в индекс
  6. Сделать начальный commit с сообщением "Initial commit: Project {description}"
  7. Если git недоступен или уже есть репозиторий - логировать предупреждение, но не прерывать создание проекта

**Интеграция с базой данных**:
- Использовать `CodeDatabase` для хранения проектов
- Синхронизировать с файлами projectid на диске

**Действия**:
1. Создать класс `ProjectManager`
2. Реализовать методы управления проектами
3. Добавить метод `create_project()` с опцией `init_git`
4. Интегрировать с `git_integration.py`
5. Интегрировать с базой данных
6. Добавить тесты

---

### Этап 5: Унификация нормализации путей

**Файл**: `code_analysis/core/path_normalization.py` (новый)

**Единый метод**: `normalize_file_path(file_path: str | Path, project_root: Optional[Path] = None) -> NormalizedPath`

**Структура возврата**:
```python
@dataclass
class NormalizedPath:
    """Normalized file path with project information."""
    absolute_path: str  # Абсолютный нормализованный путь
    project_root: Path  # Корень проекта
    project_id: str  # ID проекта
    relative_path: str  # Относительный путь от корня проекта
```

**Требования**:
- Всегда использовать один и тот же метод нормализации
- Определять корень проекта единым методом
- Валидировать project_id из файла и базы

**Действия**:
1. Создать модуль `path_normalization.py`
2. Реализовать `normalize_file_path()` с использованием `find_project_root_for_path()`
3. Заменить все вызовы `normalize_abs_path()` на новый метод
4. Обновить все места использования

---

### Этап 6: Валидация project_id при восстановлении и обновлении

**Файлы для изменения**:
- `code_analysis/core/database/files.py` - `update_file_data()`, `add_file()`
- `code_analysis/core/file_watcher_pkg/processor.py` - `_queue_file_for_processing()`
- `code_analysis/core/vectorization_worker_pkg/chunking.py` - обработка файлов

**Логика валидации**:
1. При восстановлении/обновлении файла:
   - Определить корень проекта по пути файла
   - Загрузить project_id из projectid файла
   - Получить project_id из базы данных
   - Сравнить и выбросить `ProjectIdMismatchError`, если не совпадают

**Действия**:
1. Добавить валидацию в `update_file_data()`
2. Добавить валидацию в `add_file()`
3. Добавить валидацию в `_queue_file_for_processing()`
4. Обновить обработку ошибок

---

### Этап 7: Рефакторинг файлвочера

**Файлы для изменения**:
- `code_analysis/core/file_watcher_pkg/scanner.py`
- `code_analysis/core/file_watcher_pkg/processor.py`
- `code_analysis/core/file_watcher_pkg/base.py`

**Изменения**:
1. Использовать единый метод нормализации путей
2. Использовать единый метод определения корня проекта
3. Добавить валидацию project_id
4. Убрать дублирование логики нормализации

**Действия**:
1. Обновить `scan_directory()` для использования `normalize_file_path()`
2. Обновить `_queue_file_for_processing()` для использования единых методов
3. Добавить валидацию project_id
4. Обновить тесты

---

### Этап 8: Рефакторинг векторизатора

**Файлы для изменения**:
- `code_analysis/core/vectorization_worker_pkg/chunking.py`
- `code_analysis/core/vectorization_worker_pkg/watch_dirs.py`
- `code_analysis/core/vectorization_worker_pkg/processing.py`

**Изменения**:
1. Использовать единый метод нормализации путей
2. Использовать единый метод определения корня проекта
3. Добавить валидацию project_id

**Действия**:
1. Обновить все места обращения к файловой системе
2. Использовать `normalize_file_path()` везде
3. Добавить валидацию project_id
4. Обновить тесты

---

### Этап 9: Обновление всех мест обращения к файловой системе

**Поиск всех мест**:
- `grep -r "Path(" code_analysis/`
- `grep -r "\.read_text" code_analysis/`
- `grep -r "\.write_text" code_analysis/`
- `grep -r "\.exists()" code_analysis/`
- `grep -r "\.stat()" code_analysis/`
- `grep -r "normalize" code_analysis/`

**Действия**:
1. Составить полный список всех мест
2. Классифицировать по типам операций
3. Заменить на использование единых методов
4. Добавить валидацию где необходимо

---

### Этап 10: Детальное тестирование с покрытием 90%+

**Требования к тестированию**:
- Покрытие кода: **90%+** (измеряется через `pytest-cov`)
- Использование реальных данных из `test_data/` подкаталогов
- Интеграционные тесты на реальных проектах
- Unit тесты для всех новых компонентов
- Тесты граничных случаев и обработки ошибок

**Инструменты**:
- `pytest` - фреймворк для тестирования
- `pytest-cov` - измерение покрытия кода
- `pytest-mock` - мокирование зависимостей
- `pytest-asyncio` - тестирование асинхронного кода
- `pytest-timeout` - таймауты для долгих тестов

**Структура тестов**:

#### 10.1 Тесты констант и SettingsManager

**Файл**: `tests/test_constants.py` (новый)

**Тесты**:
1. ✅ Все константы определены и имеют правильные типы
2. ✅ Константы не изменяются (immutable)
3. ✅ SettingsManager - singleton паттерн работает
4. ✅ SettingsManager - загрузка из переменных среды
5. ✅ SettingsManager - приоритет CLI > ENV > Constants
6. ✅ SettingsManager - все настройки доступны через `get()`
7. ✅ SettingsManager - удобные свойства работают
8. ✅ SettingsManager - обработка неверных значений переменных среды
9. ✅ SettingsManager - переопределение через `set_cli_overrides()`
10. ✅ SettingsManager - значения по умолчанию из констант

**Покрытие**: 100% для `constants.py` и `settings_manager.py`

#### 10.2 Тесты исключений

**Файл**: `tests/test_exceptions.py` (новый)

**Тесты**:
1. ✅ Все исключения определены в одном файле
2. ✅ Иерархия исключений корректна
3. ✅ Исключения имеют правильные сообщения
4. ✅ Исключения содержат необходимые атрибуты
5. ✅ `ProjectIdError` - корректная обработка
6. ✅ `MultipleProjectIdError` - корректная обработка
7. ✅ `ProjectIdMismatchError` - корректная обработка
8. ✅ `ProjectNotFoundError` - корректная обработка
9. ✅ `InvalidProjectIdFormatError` - корректная обработка
10. ✅ `GitOperationError` - корректная обработка

**Покрытие**: 100% для `exceptions.py`

#### 10.3 Тесты определения корня проекта

**Файл**: `tests/test_project_root_detection.py` (новый)

**Тесты на реальных данных**:
1. ✅ Определение корня для файла в `test_data/vast_srv/` - должен найти projectid
2. ✅ Определение корня для файла в `test_data/bhlff/` - должен найти projectid
3. ✅ Определение корня для файла в `test_data/code_analysis/` - должен найти projectid
4. ✅ Определение корня для файла вне проекта - должен вернуть `None`
5. ✅ Определение корня с несколькими projectid в пути - должен выбросить `MultipleProjectIdError`
6. ✅ Определение корня с вложенными проектами - должен выбросить `NestedProjectError`
7. ✅ Определение корня с невалидным UUID в projectid - должен выбросить `InvalidProjectIdFormatError`
8. ✅ Определение корня с отсутствующим projectid - должен вернуть `None`
9. ✅ Кэширование результатов определения корня
10. ✅ Производительность определения корня на больших проектах

**Использование реальных данных**:
- `test_data/vast_srv/` - реальный проект с множеством файлов
- `test_data/bhlff/` - сложная структура с вложенными модулями
- `test_data/code_analysis/` - сам проект code_analysis

**Покрытие**: 95%+ для `project_resolution.py` и `project_discovery.py`

#### 10.4 Тесты нормализации путей

**Файл**: `tests/test_path_normalization.py` (новый)

**Тесты на реальных данных**:
1. ✅ Нормализация абсолютных путей
2. ✅ Нормализация относительных путей
3. ✅ Нормализация путей с символическими ссылками
4. ✅ Нормализация путей с `..` и `.`
5. ✅ Нормализация путей для файлов из `test_data/vast_srv/`
6. ✅ Нормализация путей для файлов из `test_data/bhlff/`
7. ✅ Восстановление абсолютного пути из относительного
8. ✅ Валидация project_id при нормализации
9. ✅ Обработка путей вне проекта
10. ✅ Производительность нормализации на больших списках файлов

**Использование реальных данных**:
- Все файлы из `test_data/vast_srv/**/*.py` (380+ файлов)
- Все файлы из `test_data/bhlff/**/*.py`
- Файлы с различными расширениями из `test_data/`

**Покрытие**: 95%+ для `path_normalization.py`

#### 10.5 Тесты менеджера проектов

**Файл**: `tests/test_project_manager.py` (новый)

**Тесты на реальных данных**:
1. ✅ Получение списка проектов из `test_data/`
2. ✅ Получение информации о проекте по ID
3. ✅ Создание нового проекта с валидным описанием
4. ✅ Создание проекта с git инициализацией
5. ✅ Создание проекта без git (когда git недоступен)
6. ✅ Валидация project_id при создании
7. ✅ Обработка дублирующихся project_id
8. ✅ Синхронизация с базой данных
9. ✅ Синхронизация с файлами projectid на диске
10. ✅ Обновление информации о проекте

**Использование реальных данных**:
- Использовать существующие проекты из `test_data/`
- Создавать временные проекты для тестирования создания

**Покрытие**: 90%+ для `project_manager.py`

#### 10.6 Тесты валидации project_id

**Файл**: `tests/test_project_id_validation.py` (новый)

**Тесты на реальных данных**:
1. ✅ Валидация при добавлении файла - совпадение project_id
2. ✅ Валидация при добавлении файла - несовпадение project_id (должна выбросить `ProjectIdMismatchError`)
3. ✅ Валидация при обновлении файла - совпадение project_id
4. ✅ Валидация при обновлении файла - несовпадение project_id (должна выбросить `ProjectIdMismatchError`)
5. ✅ Валидация при восстановлении файла - совпадение project_id
6. ✅ Валидация при восстановлении файла - несовпадение project_id (должна выбросить `ProjectIdMismatchError`)
7. ✅ Валидация для файлов из `test_data/vast_srv/`
8. ✅ Валидация для файлов из `test_data/bhlff/`
9. ✅ Обработка отсутствующего projectid файла
10. ✅ Обработка невалидного формата projectid

**Использование реальных данных**:
- Файлы из реальных проектов в `test_data/`
- Тестирование с реальной базой данных

**Покрытие**: 95%+ для всех мест валидации

#### 10.7 Интеграционные тесты файлвочера

**Файл**: `tests/test_file_watcher_integration.py` (новый)

**Тесты на реальных данных**:
1. ✅ Сканирование `test_data/vast_srv/` - все файлы найдены
2. ✅ Сканирование `test_data/bhlff/` - все файлы найдены
3. ✅ Обработка изменений файлов - нормализация путей
4. ✅ Обработка добавления файлов - валидация project_id
5. ✅ Обработка удаления файлов - корректная обработка
6. ✅ Обработка перемещения файлов - обновление путей
7. ✅ Обработка вложенных проектов - корректное обнаружение
8. ✅ Производительность сканирования больших проектов
9. ✅ Обработка ошибок при сканировании
10. ✅ Логирование операций сканирования

**Использование реальных данных**:
- Полное сканирование `test_data/vast_srv/` (632 файла)
- Полное сканирование `test_data/bhlff/`
- Тестирование на реальных изменениях файлов

**Покрытие**: 90%+ для `file_watcher_pkg/`

#### 10.8 Интеграционные тесты векторизатора

**Файл**: `tests/test_vectorization_integration.py` (новый)

**Тесты на реальных данных**:
1. ✅ Векторизация файлов из `test_data/vast_srv/` - нормализация путей
2. ✅ Векторизация файлов из `test_data/bhlff/` - валидация project_id
3. ✅ Обработка файлов с различными расширениями
4. ✅ Обработка больших файлов
5. ✅ Обработка файлов с ошибками
6. ✅ Производительность векторизации
7. ✅ Обработка ошибок при векторизации
8. ✅ Логирование операций векторизации
9. ✅ Интеграция с базой данных
10. ✅ Интеграция с FAISS индексом

**Использование реальных данных**:
- Реальные Python файлы из `test_data/vast_srv/` (380+ файлов)
- Реальные Python файлы из `test_data/bhlff/`
- Файлы с различными структурами и размерами

**Покрытие**: 90%+ для `vectorization_worker_pkg/`

#### 10.9 Тесты миграции данных

**Файл**: `tests/test_migration.py` (новый)

**Тесты**:
1. ✅ Миграция projectid из старого формата в JSON
2. ✅ Обратная совместимость со старым форматом
3. ✅ Валидация JSON формата после миграции
4. ✅ Резервное копирование перед миграцией
5. ✅ Откат при ошибках миграции
6. ✅ Миграция всех projectid файлов в `test_data/`
7. ✅ Проверка целостности данных после миграции
8. ✅ Производительность миграции
9. ✅ Обработка ошибок при миграции
10. ✅ Логирование операций миграции

**Использование реальных данных**:
- Все projectid файлы из `test_data/`
- Тестирование на копиях реальных данных

**Покрытие**: 95%+ для скрипта миграции

#### 10.10 Тесты производительности

**Файл**: `tests/test_performance.py` (новый)

**Тесты**:
1. ✅ Производительность определения корня проекта (1000+ файлов)
2. ✅ Производительность нормализации путей (1000+ путей)
3. ✅ Производительность сканирования больших проектов
4. ✅ Производительность валидации project_id (1000+ файлов)
5. ✅ Производительность кэширования
6. ✅ Производительность SettingsManager
7. ✅ Производительность менеджера проектов
8. ✅ Производительность интеграции с базой данных
9. ✅ Производительность векторизации больших проектов
10. ✅ Производительность файлвочера на больших проектах

**Использование реальных данных**:
- Полные проекты из `test_data/`
- Тестирование на реальных размерах данных

**Метрики**:
- Время выполнения операций
- Использование памяти
- Количество операций в секунду

#### 10.11 Тесты граничных случаев

**Файл**: `tests/test_edge_cases.py` (новый)

**Тесты**:
1. ✅ Пустые пути
2. ✅ Пути с недопустимыми символами
3. ✅ Очень длинные пути
4. ✅ Пути с множественными `..`
5. ✅ Пути с символическими ссылками на несуществующие файлы
6. ✅ Одновременный доступ к SettingsManager из нескольких потоков
7. ✅ Одновременное определение корня проекта для одного файла
8. ✅ Обработка поврежденных projectid файлов
9. ✅ Обработка отсутствующих директорий
10. ✅ Обработка файлов без прав доступа

**Покрытие**: 90%+ для всех граничных случаев

#### 10.12 Регрессионные тесты

**Файл**: `tests/test_regression.py` (новый)

**Тесты**:
1. ✅ Все существующие тесты проходят после рефакторинга
2. ✅ Обратная совместимость со старым API
3. ✅ Обратная совместимость со старым форматом projectid
4. ✅ Обратная совместимость с существующими конфигурациями
5. ✅ Обратная совместимость с существующими базами данных
6. ✅ Обратная совместимость с существующими индексами FAISS
7. ✅ Миграция существующих данных без потерь
8. ✅ Работа с существующими проектами из `test_data/`
9. ✅ Работа с существующими файлами из `test_data/`
10. ✅ Работа с существующими настройками

**Использование реальных данных**:
- Все существующие проекты из `test_data/`
- Существующие конфигурации
- Существующие базы данных (если есть)

**Покрытие**: 100% для регрессионных тестов

---

**Команды для запуска тестов**:

```bash
# Все тесты с покрытием
pytest tests/ --cov=code_analysis/core --cov-report=html --cov-report=term-missing --cov-fail-under=90

# Только новые тесты
pytest tests/test_constants.py tests/test_settings_manager.py tests/test_project_root_detection.py tests/test_path_normalization.py tests/test_project_manager.py tests/test_project_id_validation.py tests/test_file_watcher_integration.py tests/test_vectorization_integration.py tests/test_migration.py tests/test_performance.py tests/test_edge_cases.py tests/test_regression.py --cov=code_analysis/core --cov-report=html --cov-report=term-missing --cov-fail-under=90

# Тесты на реальных данных
pytest tests/test_*_integration.py tests/test_*_real.py -v

# Тесты производительности
pytest tests/test_performance.py -v --durations=10

# Проверка покрытия для конкретного модуля
pytest tests/ --cov=code_analysis/core/settings_manager --cov-report=term-missing
```

**Требования к покрытию**:
- Минимум 90% покрытия для всех новых модулей
- 100% покрытие для критических компонентов (SettingsManager, исключения, валидация)
- 95%+ покрытие для компонентов работы с путями и проектами
- 90%+ покрытие для интеграционных компонентов

**Действия**:
1. Создать все тестовые файлы
2. Написать тесты для каждого компонента
3. Запустить тесты на реальных данных из `test_data/`
4. Проверить покрытие кода (должно быть 90%+)
5. Исправить все ошибки и увеличить покрытие до требуемого уровня
6. Добавить тесты производительности
7. Добавить регрессионные тесты
8. Интегрировать тесты в CI/CD

---

### Этап 11: Миграция существующих данных

**Скрипт миграции**: `scripts/migrate_projectid_to_json.py`

**Действия**:
1. Найти все projectid файлы
2. Прочитать старый формат
3. Преобразовать в JSON
4. Записать обратно
5. Валидировать результат

---

### Этап 12: Обновление документации

**Файлы для обновления**:
- `docs/UNIFIED_IMPLEMENTATION_PLAN.md`
- `docs/FILE_WATCHER_ARCHITECTURE.md`
- README.md (если есть)

**Действия**:
1. Обновить описание формата projectid
2. Обновить описание методов нормализации
3. Добавить примеры использования менеджера проектов
4. Обновить архитектурные диаграммы

---

## Порядок выполнения

1. **Этап 1** - Консолидация всех исключений в один файл (фундамент)
2. **Этап 2** - Изменение формата projectid (базовая структура)
3. **Этап 3** - Единый метод определения корня (основа)
4. **Этап 3.5** - Создание файла констант (централизация хардкодов)
5. **Этап 4** - Менеджер проектов с git (управление)
6. **Этап 5** - Унификация нормализации (централизация)
7. **Этап 6** - Валидация project_id (безопасность)
8. **Этап 7** - Рефакторинг файлвочера (применение)
9. **Этап 8** - Рефакторинг векторизатора (применение)
10. **Этап 9** - Обновление всех мест (полнота)
11. **Этап 10** - Тесты (проверка)
12. **Этап 11** - Миграция (данные)
13. **Этап 12** - Документация (финализация)

---

## Критерии готовности

- [ ] Все исключения консолидированы в один файл
- [x] Все хардкоды вынесены в файл констант
- [x] Создан SettingsManager с приоритетом CLI > ENV > Constants
- [ ] Все модули обновлены для использования SettingsManager
- [ ] Формат projectid изменен на JSON с обратной совместимостью
- [ ] Единый метод определения корня проекта работает корректно
- [ ] Менеджер проектов реализован с поддержкой git
- [ ] Метод создания проекта с git работает корректно
- [ ] Нормализация путей унифицирована во всех местах
- [ ] Валидация project_id работает на всех этапах
- [ ] Файлвочер использует единые методы
- [ ] Векторизатор использует единые методы
- [ ] Все места обращения к файловой системе обновлены
- [ ] Тесты покрывают все сценарии с покрытием 90%+
- [ ] Тесты используют реальные данные из test_data/
- [ ] Интеграционные тесты на реальных проектах
- [ ] Тесты производительности выполнены
- [ ] Регрессионные тесты проходят
- [ ] Миграция данных выполнена
- [ ] Документация обновлена

---

## Риски и митигация

**Риск 1**: Миграция существующих projectid файлов на новый JSON формат
- **Митигация**: Создать миграционный скрипт для автоматического обновления всех projectid файлов

**Риск 2**: Производительность при множественных проверках project_id
- **Митигация**: Кэширование результатов определения корня проекта

**Риск 3**: Ошибки при миграции существующих projectid файлов
- **Митигация**: Резервное копирование перед миграцией, откат при ошибках

**Риск 4**: Регрессии в существующем функционале
- **Митигация**: Полное покрытие тестами перед рефакторингом, постепенное внедрение

---

## Оценка времени

- Этап 1: 4 часа (консолидация всех исключений)
- Этап 2: 4 часа
- Этап 3: 6 часов
- Этап 3.5: 6 часов (поиск и вынос всех хардкодов)
- Этап 4: 10 часов (менеджер проектов + git интеграция)
- Этап 5: 6 часов
- Этап 6: 4 часа
- Этап 7: 8 часов
- Этап 8: 6 часов
- Этап 9: 12 часов
- Этап 10: 24 часа (детальное тестирование с покрытием 90%+)
- Этап 11: 4 часа
- Этап 12: 4 часа

**Итого**: ~94 часа работы (включая детальное тестирование)

---

## Детальный анализ хардкодов в проекте

### Найденные хардкоды

**Строковые константы**:
- `"__pycache__"`, `".git"`, `".pytest_cache"`, `".mypy_cache"`, `"node_modules"`, `".venv"`, `"venv"` - паттерны игнорирования
- `"projectid"` - имя файла projectid
- `"data/versions"`, `"data/locks"`, `"logs/"`, `"data/"` - пути к директориям
- `"*.pyc"`, `"*.py"`, `".json"`, `".yaml"`, `".yml"`, `".toml"`, `".ini"`, `".cfg"` - расширения файлов
- `"TODO"`, `"FIXME"`, `"XXX"`, `"HACK"`, `"NOTE"`, `"BUG"`, `"OPTIMIZE"`, `"PLACEHOLDER"`, `"STUB"`, `"NOT IMPLEMENTED"` - паттерны плейсхолдеров
- `"data/code_analysis.db"`, `"data/faiss"`, `"data/dynamic_watch_dirs.json"` - пути к файлам
- `"logs/vectorization_worker.log"`, `"logs/file_watcher.log"` - пути к логам
- `"0.0.0.0"` - хост сервера по умолчанию
- `"sqlite_proxy"` - тип драйвера базы данных

**Числовые константы**:
- `400` - максимальное количество строк в файле
- `30` - минимальная длина чанка, интервал опроса (секунды)
- `60` - интервал сканирования (секунды), таймаут восстановления (секунды), таймаут команды (секунды)
- `10` - размер батча, задержка повтора (секунды), таймаут git команд (секунды)
- `3` - количество попыток повтора, максимальное количество пустых итераций
- `5` - порог отказов, количество резервных копий логов, задержка (секунды), максимальное количество попыток подключения к БД
- `2` - порог успешных запросов, множитель задержки, задержка между попытками подключения к БД (секунды)
- `300` - максимальная задержка (секунды), максимальная длительность сканирования (секунды)
- `10485760` - максимальный размер лог-файла (10 MB)
- `384` - размерность вектора
- `15000` - порт сервера по умолчанию
- `8009` - порт чанкера по умолчанию
- `8001` - порт сервиса эмбеддингов по умолчанию
- `0.1` - толерантность для сравнения времени модификации файлов (секунды)
- `0.001` - эпсилон для обновления last_modified
- `1.0` - интервал опроса для proxy драйвера (секунды)

**Пути и имена файлов**:
- Все пути к директориям и файлам должны быть вынесены в константы
- Все расширения файлов должны быть в константах
- Все имена файлов (projectid, .gitignore) должны быть в константах

**Места использования хардкодов**:
- `code_analysis/core/file_watcher_pkg/scanner.py`: `CODE_FILE_EXTENSIONS`, `DEFAULT_IGNORE_PATTERNS`
- `code_analysis/core/comprehensive_analyzer.py`: `PLACEHOLDER_PATTERNS` (хардкод в коде)
- `code_analysis/core/config.py`: все значения по умолчанию
- `code_analysis/core/storage_paths.py`: пути к директориям
- `code_analysis/core/vectorization_worker_pkg/runner.py`: значения по умолчанию для параметров
- `code_analysis/main.py`: таймауты и интервалы для подключения к БД
- Все места, где используются числовые константы без объяснения

---

## Детальный анализ мест обращения к файловой системе

### Файлвочер (file_watcher_pkg)

**scanner.py**:
- `scan_directory()`: `root_dir.rglob("*")`, `item.stat()`, `normalize_abs_path(item)`, `find_project_root()`
- `should_ignore_path()`: `path.parts`, `path.is_absolute()`, `path.is_dir()`, `path.is_file()`

**processor.py**:
- `_queue_file_for_processing()`: `normalize_abs_path()`, `Path(abs_file_path).exists()`, `path_obj.read_text()`
- `_get_project_root_dir()`: `Path(file_path).resolve()`

**base.py**:
- `_scan_cycle()`: `scan_directory()` (косвенно)

**multi_project_worker.py**:
- `_scan_watch_dir()`: `watch_dir.exists()`, `scan_directory()`

### Векторизатор (vectorization_worker_pkg)

**chunking.py**:
- `_request_chunking_for_files()`: `Path(file_path)`, `file_path_obj.exists()`, `file_path_obj.read_text()`

**watch_dirs.py**:
- `_refresh_config()`: `self.dynamic_watch_file.exists()`, `open()`, `self.config_path.exists()`, `self.config_path.stat()`
- `_enqueue_watch_dirs()`: `Path(root)`, `root_path.exists()`, `root_path.rglob("*.py")`, `file_path.stat()`, `file_path.read_text()`

**processing.py**:
- Использует методы из chunking.py и watch_dirs.py

### Проект резолюшн (project_resolution.py)

- `normalize_root_dir()`: `Path(root_dir).expanduser().resolve()`, `root_path.exists()`, `root_path.is_dir()`
- `normalize_abs_path()`: `Path(path).expanduser().resolve()`
- `load_project_id()`: `normalize_root_dir()`, `pid_path.exists()`, `pid_path.read_text()`

### Проект дискавери (project_discovery.py)

- `find_project_root()`: `Path(file_path).resolve()`, `file_path.exists()`, `projectid_path.exists()`, `load_project_id()`
- `validate_no_nested_projects()`: `Path()`, `projectid_path.exists()`
- `discover_projects_in_directory()`: `Path(watch_dir).resolve()`, `watch_dir.exists()`, `watch_dir.is_dir()`, `watch_dir.rglob("projectid")`, `projectid_path.is_file()`

### База данных (database/files.py)

- `add_file()`: `normalize_abs_path()`
- `get_file_by_path()`: `normalize_abs_path()`
- `update_file_data()`: `normalize_abs_path()`, `Path(abs_path)`, `file_path_obj.exists()`, `file_path_obj.stat()`
- `mark_file_deleted()`: `normalize_abs_path()`, `Path(abs_path)`, `original_path.exists()`, `shutil.move()`
- `vectorize_file_immediately()`: `Path(file_path)`, `file_path_obj.exists()`, `file_path_obj.read_text()`

### Команды (commands/)

**code_mapper_mcp_command.py**:
- `_analyze_file()`: `Path(file_path)`, `file_path.exists()`, `file_path.read_text()`

**base_mcp_command.py**:
- `_validate_root_dir()`: `normalize_root_dir()`
- `_validate_file_path()`: `Path()`, `file_path.exists()`

**project_management_mcp_commands.py**:
- Различные операции с проектами, использование `normalize_root_dir()`

---

## Примечания

- Все изменения должны быть обратно совместимыми
- Тесты должны быть написаны перед рефакторингом (TDD подход)
- **КРИТИЧНО**: Покрытие тестами должно быть 90%+ для всех новых компонентов
- **КРИТИЧНО**: Все тесты должны использовать реальные данные из `test_data/` подкаталогов
- **КРИТИЧНО**: Интеграционные тесты должны выполняться на реальных проектах (vast_srv, bhlff, code_analysis)
- Каждый этап должен быть завершен и протестирован перед переходом к следующему
- Документация должна обновляться параллельно с кодом

## Дополнительные требования

1. **Кэширование**: Результаты определения корня проекта должны кэшироваться для производительности
2. **Логирование**: Все операции с путями должны логироваться для отладки
3. **Метрики**: Собирать метрики по времени выполнения операций нормализации
4. **Валидация**: Все пути должны валидироваться на каждом этапе

